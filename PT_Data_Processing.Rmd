---
title: "PT Data Processing Workbook"
output:
  html_document:
    df_print: paged
  html_notebook:
    fig_width: 6
---

To do: add check for site name and instrument names...

    The goal of this notebook is to organize, process, and QAQC raw pressure transducer data. To use this worksheet, save it in the directory of interest.  This directory should contain both an export folder and well log file. The export folder should contain .csv files with raw pressure values exported from the HOBO software, and the well log file contains pertinant informtation such as well name, associated baro logger file, and water level dimensions. 
    
    Below are breif descriptions of each code chunk:
    1.  Setup: Point to working directory, read well log file, and create temp file
    2.  PT-data-wrangling: Read PT file, check units, deal with time variable, and print temp file.
    3.  Baro-data-wrangling: Same as (2) above, except for baro file.
    4.  Water-level-calculation: Convert pressure to water level.
    
    Coming Soon:
    5.  Interact with database (pull relative water level, previous ts data, etc)
    6.  Examine "offset", add updated offset [do this by HAND]
    7.  QAQC time series 
    8.  Insert into database

    Once you have completed the worksheet, delete this text and add notes here!  Save for your lab mates and future self. :)

```{r setup, include=FALSE}
#Clear Memory
rm(list=ls(all=TRUE))

#Load Required Packages
library(dplyr)   
library(devtools)
library(RSQLite)
library(DBI)

#Load Palmer Lab tools
source("db_get_water_level_ts.R")
devtools::install_github("khondula/rodm2")
library(rodm2)

#Define working directory and database location
working_dir<-"//nfs/palmer-group-data/Choptank/Nate/PT_Data/20171020_Downloads/"
db_loc<-"//nfs/palmer-group-data/Choptank/Nate/PT_Data/odm2.sqlite"

#Download Data
master<-read.csv(paste0(working_dir,"well_log.csv"))

#Create temp file
dir.create(paste0(working_dir,"temp"))

#Connect to database
db<-dbConnect(SQLite(), paste0(db_loc))
```

```{r initial-checks, echo=F}
#Check to make sure site names are in DB-----------------------------------------------------------------------
a<-as.matrix(master[,"Site_Name"], ncol=1)
b<-as.matrix(dbGetQuery(db,"SELECT SamplingFeatureCode FROM SamplingFeatures"))
if(length(a[!(a %in% b)])!=0){
  warning(paste0("Site Names in Well Log and Database do not match!!"))
  print(a[!(a %in% b)])
}else{
  "Site Names Match!"
}

#Check to make sure Sonde ID in well log and Serial Number in files match--------------------------------------
fun<-function(n){
  #Read data
  temp<-read.csv(paste0(working_dir,"export/", logs[n]), skip=1)
  
  #extract serial number
  serial_number<-colnames(temp)[grep("LGR",colnames(temp))][1]  #Find collumn name with serial number
  serial_number<-substr(serial_number,   #isolate serial number
                        gregexpr("SEN.S.N",serial_number)[[1]][1]+9, #Start
                        nchar(serial_number)-1) #stop
  serial_number<-as.numeric(serial_number) 
  
  #export serial number
  serial_number
}
#Create list of files 
logs<-list.files(paste0(working_dir,"export"))
a<-sapply(seq(1,length(logs)), fun)  
b<-master$Sonde_ID  
if(length(a[!(a %in% b)])!=0){
  warning(paste0("Sonde serial number in Well Log and data files do not match!!"))
  print(a[!(a %in% b)])
}else{
  "Serial Numbers Match"
}

#Check units in files------------------------------------------------------------------------------------------
#Create functoin to check units in file
fun<-function(n){
  #Donwload data
  temp<-read.csv(paste0(working_dir,"export/", logs[n]), skip=1)
  
  #Check pressure units
  press_units<-colnames(temp)[grep("kPa",colnames(temp))][1] 
  press_units<-substr(press_units,   #isolate temperature units
                     gregexpr("Abs.Pres", press_units)[[1]][1]+10, #Start
                     gregexpr("Abs.Pres", press_units)[[1]][1]+12) #stop

  #Check temp units
  temp_units<-colnames(temp)[grep("Temp",colnames(temp))][1] 
  temp_units<-substr(temp_units,   #isolate temperature units
                     gregexpr("Temp", temp_units)[[1]][1]+7, #Start
                     gregexpr("Temp", temp_units)[[1]][1]+7) #stop
  
  #Print units
  data.frame(filename=logs[n], 
             pressure=press_units, 
             temperature=temp_units)
}
x<-lapply(seq(1, length(logs)), fun)
x<-data.frame(do.call(rbind,x))
print(x)
```

```{r pt-data-wrangling,echo=F}
#create function to download logs, clean, and rewrite in temp folder
fun<-function(n){
  #Setup~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #Read data
  df<-read.csv(paste0(working_dir,"export/", logs[n]), skip=1)
  
  #Define serial number
  serial_number<-colnames(df)[grep("LGR",colnames(df))][1]  #Find collumn name with serial number
  serial_number<-substr(serial_number,   #isolate serial number
                        gregexpr("SEN.S.N",serial_number)[[1]][1]+9, #Start
                        nchar(serial_number)-1) #stop
  serial_number<-as.numeric(serial_number) 
  
  #Determine timezone offset in seconds
  time_offset<-colnames(df)[grep("GMT",colnames(df))]  #Grab collumn name w/ time offset
  time_offset<-as.numeric(substr(time_offset, 16,18))*3600+as.numeric(substr(time_offset, 19,20))*60
  
  #Define variables from well log
  site_name<-master$Site_Name[master$Sonde_ID==serial_number]
  deployment<-strptime(paste(master$Date[master$Sonde_ID==serial_number],
                             master$Time[master$Sonde_ID==serial_number]), 
                       format="%m/%d/%Y %H:%M", tz="GMT")
  deployment<-deployment-time_offset
  relative_wl<-master$Relative_Water_Level_m[master$Sonde_ID==serial_number]
  baro_file<-master$baro_file[master$Sonde_ID==serial_number]
  
  #water level time sereis~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #subset dataframe to temp, abs_pres, and temp
  df<-df[,c(2,3,4)]
  colnames(df)<-c("Timestamp", "pressureAbsolute", "temp_c")
  
  #format date_time
  df$Timestamp<-strptime(df$Timestamp, "%m/%d/%y %I:%M:%S %p")-time_offset
  df$Timestamp<-as.POSIXct(df$Timestamp)
  
  #baro file time series~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #Subset dataframe to temp, abs_pres, and temp
  baro<-read.csv(paste0(working_dir,"export/", baro_file), skip=1)
  baro<-baro[,c(2,3,4)]
  colnames(baro)<-c("Timestamp", "barometricPressure", "temp_c")
  
  #format date and time
  baro$Timestamp<-strptime(baro$Timestamp, "%m/%d/%y %I:%M:%S %p")-time_offset
  baro$Timestamp<-as.POSIXct(baro$Timestamp)
  
  #Cacluculate waterlevel~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #create baro interpolation function
  baro_fun<-approxfun(baro$Timestamp, baro$barometricPressure)
  
  #calculate baro for each df time step
  df$barometricPressure<-baro_fun(df$Timestamp)
  
  #Cacluate gage pressure
  df$pressureGauge<-df$pressureAbsolute-df$barometricPressure
  
  #Calculate relative water level
  df$gageHeight<-df$pressureGauge/9.81
  
  #Water Level
  df$waterLevel<-df$gageHeight+relative_wl
  
  #Prune water level based on deployment time
  df<-df[df$Timestamp<deployment,]
  df<-na.omit(df)
  
  #Write df to temp file
  write.csv(df, paste0(working_dir,"intermediate/", serial_number,".csv"))
}

#Create list of PT files
logs<-list.files(paste0(working_dir,"export"))

#create temp file to store intermediate files
dir.create(paste0(working_dir,"intermediate"))

#Run function 
lapply(seq(1, length(logs)), fun)
```


```{r db-upload, echo=F}
#Create function to upload relevant data into database
fun<-function(n){
  #define PT serioal number
  serial_number<-as.numeric(paste(substr(logs[n],1, nchar(logs[n])-15)))
  site<-master$Site.Name[master$Sonde_ID==serial_number]
  
  #Read PT file
  df<-read.csv(paste0(working_dir,"temp/",logs[n]))
  df$DateTime_GMT<-(as.POSIXct(df$DateTime_GMT))
  df$Timestamp<-df$DateTime_GMT
  
  #format pt file
  df<-df[,c("Timestamp","abs_pres_kPa","atm_pres_kPa","gage_pres_kPa","water_level_m")]
  df<-as_tibble(df)
  
  #Create variable list
  vars_list<-list("abs_pres_kPa",
                  "atm_pres_kPa" ,
                  "gage_pres_kPa" ,
                  "water_level_m" 
                  )
  
  #Connect to database
  db<-dbConnect(RSQLite::SQLite(), paste0(db_loc))
  
  #Upload to database!
  db_insert_results_ts(db = db, # database connecton
                       datavalues = df, # data frame of time series data
                       method = "PT Data Download", 
                       site_code = site, 
                       variables = vars_list, 
                       sampledmedium = "Water"#, # from medium controlled vocabulary
                       #actionby = "Nate", # optional
                       #equipment_name = serial_number # optional
                       )
  #Notes
    #Need to addd myself to the database before entering
    #there seems to be a glitch with equipment name
    #if you use "describe" function before hand, you only put variable name in variables list
  
  #Disconnect from database
  RSQLite::dbDisconnect(db)
}

#Create list of PT files 
logs<-list.files(paste0(working_dir,"temp/"))
logs<-logs[grep("_waterlevel",logs)]

#Run function 
output<-lapply(seq(1, length(logs)), fun)
```














    Workign space below




From here, remove 1 hour within download
Setup interactive plots
Insert into database




```{r, fig.width=12}
#Read libraries
library(dygraphs)
library(ggplot2)
library(xts)

dygraph(df) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  #dyRoller(rollPeriod = 5) %>% 
  dyAxis("y", label = "Water Level [m]")

```



```{r}
#Read libraries
library(dygraphs)
library(ggplot2)
library(xts)

#subset master to just wetlands (for now...)
master<-master[grep("Wetland Well Shallow",master$Site.Name),]

#Gather Data
for(i in 1:length(master[,1])){
  print(i)
  serial_number<-master$Sonde_ID[i]
  temp<-read.csv(paste0("initial_processing/",serial_number,".csv"))
  temp<-temp[,c("DateTime_GMT","level_m")]
  temp$site<-substr(master$Site.Name[i],1,2)
  temp$DateTime_GMT<-strptime(temp$DateTime_GMT,"%Y-%m-%d %H:%M:%S")
  temp<-temp[-c(1:5),]
  temp<-na.omit(temp)
  temp_max<-max(temp$level_m)
  temp$level_rel<-temp$level_m/temp_max
  if(i==1){
    df<-temp
  }else{
    df<-rbind(df,temp)
  }
}

#Format df
df_spread <- df %>% 
    dplyr::select(DateTime_GMT, site, level_rel) %>%
    tidyr::spread(key = site, value = level_rel)
df_xts<-xts(df_spread, order.by=df_spread$DateTime_GMT)
df_xts<-df_xts[,-1]

#Plot
dygraph(df_xts, main = "Jackson Lane Wetland Water Level") %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  #dyRoller(rollPeriod = 5) %>% 
  dyHighlight(highlightCircleSize = 5, 
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Relative Water Level [% of max]")#, valueRange=c(1.6,2.1))
```

