---
title: "PT Data Processing Workbook"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
  html_notebook:
    fig_width: 6
    toc: yes
    toc_float: yes
---

To do: add check for site name and instrument names...

#Notes and Setup

    The goal of this notebook is to organize, process, and QAQC raw pressure transducer data. To use this worksheet, save it in the directory of interest.  This directory should contain both an export folder and well log file. The export folder should contain .csv files with raw pressure values exported from the HOBO software, and the well log file contains pertinant informtation such as well name, associated baro logger file, and water level dimensions. 
    
    Below are breif descriptions of each code chunk:
    1.  Setup: Point to working directory, read well log file, and create temp file
    2.  Initial Checks: Make sure well log sheet is accurate, check   
    3.  PT-data-wrangling: Read PT file, substract baro pressure, calculate water level
    4.  Individual QAQC checks. [For now, you will need to cut & paste this for each well...]
    5.  Function to import data into the database. 

    Once you have completed the worksheet, delete this text and add notes here!  Save for your lab mates and future self. :)

```{r setup, echo=FALSE, results="hide", warning=FALSE, message=FALSE}
#Clear Memory
rm(list=ls(all=TRUE))

#Load Required Packages
library(dplyr)   
library(devtools)
library(RSQLite)
library(DBI)
library(xts)
library(dygraphs)

#Load Palmer Lab tools
source("db_get_water_level_ts.R")
devtools::install_github("khondula/rodm2")
library(rodm2)

#Define working directory and database location
working_dir<-"//nfs/palmer-group-data/Choptank/Nate/PT_Data/20171020_Downloads/"
db_loc<-"//nfs/palmer-group-data/Choptank/Nate/PT_Data/odm2.sqlite"

#Download Data
master<-read.csv(paste0(working_dir,"well_log.csv"))

#Create temp file
dir.create(paste0(working_dir,"intermediate"))

#Connect to database
db<-dbConnect(SQLite(), paste0(db_loc))
```

```{r initial-checks, echo=FALSE, results="hide"}
#Check to make sure site names are in DB-----------------------------------------------------------------------
a<-as.matrix(master[,"Site_Name"], ncol=1)
b<-as.matrix(dbGetQuery(db,"SELECT SamplingFeatureCode FROM SamplingFeatures"))
if(length(a[!(a %in% b)])!=0){
  warning(paste0("Site Names in Well Log and Database do not match!!"))
  print(a[!(a %in% b)])
}else{
  "Site Names Match!"
}

#Check to make sure Sonde ID in well log and Serial Number in files match--------------------------------------
fun<-function(n){
  #Read data
  temp<-read.csv(paste0(working_dir,"export/", logs[n]), skip=1)
  
  #extract serial number
  serial_number<-colnames(temp)[grep("LGR",colnames(temp))][1]  #Find collumn name with serial number
  serial_number<-substr(serial_number,   #isolate serial number
                        gregexpr("SEN.S.N",serial_number)[[1]][1]+9, #Start
                        nchar(serial_number)-1) #stop
  serial_number<-as.numeric(serial_number) 
  
  #export serial number
  serial_number
}
#Create list of files 
logs<-list.files(paste0(working_dir,"export"))
a<-sapply(seq(1,length(logs)), fun)  
b<-master$Sonde_ID  
if(length(a[!(a %in% b)])!=0){
  warning(paste0("Sonde serial number in Well Log and data files do not match!!"))
  print(a[!(a %in% b)])
}else{
  "Serial Numbers Match"
}

#Check units in files------------------------------------------------------------------------------------------
#Create functoin to check units in file
fun<-function(n){
  #Donwload data
  temp<-read.csv(paste0(working_dir,"export/", logs[n]), skip=1)
  
  #Check pressure units
  press_units<-colnames(temp)[grep("kPa",colnames(temp))][1] 
  press_units<-substr(press_units,   #isolate temperature units
                     gregexpr("Abs.Pres", press_units)[[1]][1]+10, #Start
                     gregexpr("Abs.Pres", press_units)[[1]][1]+12) #stop

  #Check temp units
  temp_units<-colnames(temp)[grep("Temp",colnames(temp))][1] 
  temp_units<-substr(temp_units,   #isolate temperature units
                     gregexpr("Temp", temp_units)[[1]][1]+7, #Start
                     gregexpr("Temp", temp_units)[[1]][1]+7) #stop
  
  #Print units
  data.frame(filename=logs[n], 
             pressure=press_units, 
             temperature=temp_units)
}
x<-lapply(seq(1, length(logs)), fun)
x<-data.frame(do.call(rbind,x))
print(x)
```

```{r pt-data-wrangling, echo=FALSE, results="hide"}
#create function to download logs, clean, and rewrite in temp folder
fun<-function(n){
  #Setup~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #Read data
  df<-read.csv(paste0(working_dir,"export/", logs[n]), skip=1)
  
  #Define serial number
  serial_number<-colnames(df)[grep("LGR",colnames(df))][1]  #Find collumn name with serial number
  serial_number<-substr(serial_number,   #isolate serial number
                        gregexpr("SEN.S.N",serial_number)[[1]][1]+9, #Start
                        nchar(serial_number)-1) #stop
  serial_number<-as.numeric(serial_number) 
  
  #Determine timezone offset in seconds
  time_offset<-colnames(df)[grep("GMT",colnames(df))]  #Grab collumn name w/ time offset
  time_offset<-as.numeric(substr(time_offset, 16,18))*3600+as.numeric(substr(time_offset, 19,20))*60
  
  #Define variables from well log
  site_name<-master$Site_Name[master$Sonde_ID==serial_number]
  deployment<-strptime(paste(master$Date[master$Sonde_ID==serial_number],
                             master$Time[master$Sonde_ID==serial_number]), 
                       format="%m/%d/%Y %H:%M", tz="GMT")
  deployment<-deployment-time_offset
  relative_wl<-master$Relative_Water_Level_m[master$Sonde_ID==serial_number]
  baro_file<-master$baro_file[master$Sonde_ID==serial_number]
  
  #water level time sereis~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #subset dataframe to temp, abs_pres, and temp
  df<-df[,c(2,3,4)]
  colnames(df)<-c("Timestamp", "pressureAbsolute", "temp_c")
  
  #format date_time
  df$Timestamp<-strptime(df$Timestamp, "%m/%d/%y %I:%M:%S %p")-time_offset
  df$Timestamp<-as.POSIXct(df$Timestamp)
  
  #baro file time series~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #Subset dataframe to temp, abs_pres, and temp
  baro<-read.csv(paste0(working_dir,"export/", baro_file), skip=1)
  baro<-baro[,c(2,3,4)]
  colnames(baro)<-c("Timestamp", "barometricPressure", "temp_c")
  
  #format date and time
  baro$Timestamp<-strptime(baro$Timestamp, "%m/%d/%y %I:%M:%S %p")-time_offset
  baro$Timestamp<-as.POSIXct(baro$Timestamp)
  
  #Cacluculate waterlevel~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #create baro interpolation function
  baro_fun<-approxfun(baro$Timestamp, baro$barometricPressure)
  
  #calculate baro for each df time step
  df$barometricPressure<-baro_fun(df$Timestamp)
  
  #Cacluate gage pressure
  df$pressureGauge<-df$pressureAbsolute-df$barometricPressure
  
  #Calculate relative water level
  df$gageHeight<-df$pressureGauge/9.81
  
  #Water Level
  df$waterLevel<-df$gageHeight+relative_wl
  
  #Prune water level based on deployment time
  df<-df[df$Timestamp<deployment,]
  df<-na.omit(df)
  
  #Write df to temp file
  write.csv(df, paste0(working_dir,"intermediate/", serial_number,".csv"))
}

#Create list of PT files
logs<-list.files(paste0(working_dir,"export"))

#create temp file to store intermediate files
dir.create(paste0(working_dir,"intermediate"))

#Run function 
lapply(seq(1, length(logs)), fun)
```

#Water Level QAQC
##DB Wetland Well Shallow
This is preliminary data and will undergo more rigurous QAQC at a later date. 
```{r DB-Wetland-Well-Shallow, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-1

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```





##TA Wetland Well Shallow
This is preliminary data and will undergo more rigurous QAQC at a later date. 
```{r TA-Wetland-Well-Shallow, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-2

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```

##TB Wetland Well Shallow
This is preliminary data and will undergo more rigurous QAQC at a later date. 
```{r TB-Wetland-Well-Shallow, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-3

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```

##Tiger Paw Catchment Outlet
This is preliminary data and will undergo more rigurous QAQC at a later date. 
```{r Tiger Paw Catchment Outlet, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-4

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```


##FN Wetland Well Shallow
This is preliminary data and will undergo more rigurous QAQC at a later date. 
  #1) Removed data before September 2017 at 8:00 AM. This data was collected before the sonde was deployed.
```{r FN-Wetland-Well-Shallow, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-5

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Other QAQC Procedures [Include in notes above!]
#Remove initial data whne sonde was out of the water
df<-df[df$Timestamp>as.POSIXct("2017-09-27 08:00"),]

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```

##BB Wetland Well Shallow
This is preliminary data and will undergo more rigurous QAQC at a later date. 
    1) The offset seems to be wrong here. [maybe this was a bad measurement?]
```{r BB Wetland Well Shallow, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-6

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```




##Mikey Likey Catchment Outlet
This is preliminary data and will undergo more rigurous QAQC at a later date. 
  Note, we used Mikey Likey as the baro logger in the initial deployment. I want to check it against another [local?] baro troll to mkae sure this is ok...
```{r Mikey Like Catchment Outlet, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-7

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```




##TB Upland Well 2
This is preliminary data and will undergo more rigurous QAQC at a later date. 
```{r TB Upland Well 2, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-8

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```






##TB Upland Well 1
This is preliminary data and will undergo more rigurous QAQC at a later date. 
  #1) Removed data before 9-27-2017 06:20 AM when logger was deployed.
```{r TB Upland Well 1, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-9

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Other QAQC
df<-df[df$Timestamp>as.POSIXct("2017-09-27 06:20"),]

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```




##DK Upland Well 2
This is preliminary data and will undergo more rigurous QAQC at a later date. 

```{r DK Upland Well 2, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-10

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Other QAQC
#df<-df[df$Timestamp>as.POSIXct("2017-09-27 06:20"),]

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```




##DK Wetland Well Shallow
This is preliminary data and will undergo more rigurous QAQC at a later date. 

```{r DK Wetland Well Shallow, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-11

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Other QAQC
#df<-df[df$Timestamp>as.POSIXct("2017-09-27 06:20"),]

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```




##DK Upland Well 1
This is preliminary data and will undergo more rigurous QAQC at a later date. 

```{r DK Upland Well 1, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-12

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Other QAQC
#df<-df[df$Timestamp>as.POSIXct("2017-09-27 06:20"),]

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```




##ND Upland Well 1
This is preliminary data and will undergo more rigurous QAQC at a later date. 

```{r ND Upland Well 1, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-13

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Other QAQC
#df<-df[df$Timestamp>as.POSIXct("2017-09-27 06:20"),]

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```



##ND Upland Well 2
This is preliminary data and will undergo more rigurous QAQC at a later date. 

```{r ND Upland Well 2, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-14

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Other QAQC
#df<-df[df$Timestamp>as.POSIXct("2017-09-27 06:20"),]

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```



##ND Wetland Well Shallow
This is preliminary data and will undergo more rigurous QAQC at a later date. 

```{r ND Wetland Well Shallow, echo=F}
#Setup----------------------------------------------------------------------  
#For now, we are going to cut and paste this for each well.  Eventually, I would like to create a shyiny app + more optimization. Actually, since I"m wildly brainstorming...it would be BA to create a shiny app to (1) define the shift and (2) clip bad pieces of data.   

#define well 
n<-15

#Plot----------------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)
df$waterLevel<-df$waterLevel*100+1000 

#pull water level from database
df_historic<-db_get_water_level_ts(paste(master$Site_Name[1]))

#Format df
if(length(df_historic)==0){
  df <- df %>% select(Timestamp, waterLevel)
  df_xts<-xts(df, order.by=df$Timestamp)
  df_xts<-df_xts[,-1]
}else{
  #add datum correction to df_historic
  df_historic$waterLevel<-df_historic$waterLevel+1000  
  df_historic$group<-"old"
  df$group<-"new"
  df<-rbind(df_historic, df)
  df_spread <- df %>% 
     dplyr::select(Timestamp, group, waterLevel) %>%
     tidyr::spread(key = group, value = waterLevel)
  df_xts<-xts(df_spread, order.by=df_spread$Timestamp)
  df_xts<-df_xts[,-1]
  }

#Plot
dygraph(df_xts, main=master$Site_Name[n]) %>%
  dyRangeSelector() %>%
  dyLegend() %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyOptions(labelsUTC = TRUE) %>%
  dyHighlight(highlightCircleSize = 5,
                  highlightSeriesBackgroundAlpha = 0.2,
                  hideOnMouseOut = FALSE) %>%
  dyAxis("y", label = "Water Level [cm]")

#Define Offset----------------------------------------------------------------
#Read df
df<-read.csv(paste0(working_dir, "intermediate/",master$Sonde_ID[n],".csv"))
df$Timestamp<-as.POSIXct(df$Timestamp)

#define offset and export
df$offset<-0
df$waterLevel<-df$waterLevel+df$offset

#Other QAQC
#df<-df[df$Timestamp>as.POSIXct("2017-09-27 06:20"),]

#Export to csv 
write.csv(df, paste0(working_dir, "intermediate/", master$Sonde_ID[n],"_processed.csv"))
```


#Database Import
```{r database import, echo=FALSE}
#Create function
fun<-function(n){
  #Download intermediate ts data
  df<-read.csv(paste0(working_dir,"intermediate/", logs[n]))
  df<-df[,c("Timestamp","waterLevel")]
  df$Timestamp<-as.POSIXct(df$Timestamp)
  
  #Create variable list
  vars_list<-list(#"pressureAbsolute"    = list(column = "pressureAbsolute",   units = "KPa"),
                  #"barometricPressure"  = list(column = "barometricPressure", units = "KPa"),
                  #"pressureGauge"       = list(column = "pressureGauge",      units = "KPa"),
                  #"gageHeight"          = list(column = "gageHeight",         units = "Meter"),
                  "waterLevel"          = list(column = "waterLevel",         units = "Meter"))#,
                  #"offset"              = list(column = "offset",             units = "Meter"))

  #Insert data into database
  db_insert_results_ts(db = db, # database connecton
                       datavalues = df, # data frame of time series data
                       method = "PT Data Download", 
                       site_code = master$Site_Name[n], 
                       variables = vars_list, 
                       sampledmedium = "Water",
                       actionby = "Margaret",
                       equipment_name = as.character(master$Sonde_ID[n]))
}

#Create list of intermediate files
logs<-list.files(paste0(working_dir,"intermediate"))
logs<-logs[grep("processed", logs)]

#Run function
t0<-Sys.time()
lapply(seq(1, length(logs)), fun)
tf<-Sys.time()

RSQLite::dbDisconnect(db)
```

